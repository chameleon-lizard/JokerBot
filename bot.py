import os
import json
import telebot
import logging
import uuid
from dotenv import load_dotenv
from openai import OpenAI
from qdrant_client import QdrantClient, models
from sentence_transformers import SentenceTransformer
from telebot.types import InlineKeyboardMarkup, InlineKeyboardButton

# --- Load Configuration ---
load_dotenv()
BOT_TOKEN = os.getenv("BOT_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_BASE_URL = os.getenv("OPENAI_BASE_URL")
QDRANT_PATH = os.getenv("QDRANT_PATH")
QDRANT_COLLECTION_NAME = os.getenv("QDRANT_COLLECTION_NAME")

# --- Constants ---
LOG_FILE = 'jokes_log.json'

# --- Validate Configuration ---
for var in [BOT_TOKEN, OPENAI_API_KEY, OPENAI_BASE_URL, QDRANT_PATH, QDRANT_COLLECTION_NAME]:
    if not var:
        raise ValueError(f"Environment variable for {var} is not set. Please check your .env file.")

# --- Initialize Services ---
bot = telebot.TeleBot(BOT_TOKEN)
logger = telebot.logger
telebot.logger.setLevel(logging.INFO)

openai_client = OpenAI(api_key=OPENAI_API_KEY, base_url=OPENAI_BASE_URL)
qdrant_client = QdrantClient(path=QDRANT_PATH)
embedding_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')

# In-memory storage for sent jokes to track votes
jokes_sent = {}

# --- JSON Logging Functions ---
def append_log_entry(entry):
    """Appends a new log entry to the JSON log file."""
    try:
        with open(LOG_FILE, 'r+', encoding='utf-8') as f:
            logs = json.load(f)
            logs.append(entry)
            f.seek(0)
            json.dump(logs, f, ensure_ascii=False, indent=4)
    except (FileNotFoundError, json.JSONDecodeError):
        with open(LOG_FILE, 'w', encoding='utf-8') as f:
            json.dump([entry], f, ensure_ascii=False, indent=4)

def update_log_rating(joke_id, rating):
    """Updates the rating for a specific joke in the JSON log file."""
    try:
        with open(LOG_FILE, 'r+', encoding='utf-8') as f:
            logs = json.load(f)
            for entry in logs:
                if entry.get('id') == joke_id:
                    entry['rating'] = rating
                    break
            f.seek(0)
            f.truncate()
            json.dump(logs, f, ensure_ascii=False, indent=4)
    except (FileNotFoundError, json.JSONDecodeError):
        logger.error(f"Could not update rating. Log file '{LOG_FILE}' not found or is corrupted.")

# --- Qdrant Setup Function ---
def setup_qdrant():
    """Initializes the Qdrant collection, populating it if it doesn't exist."""
    try:
        qdrant_client.get_collection(collection_name=QDRANT_COLLECTION_NAME)
        logger.info(f"Qdrant collection '{QDRANT_COLLECTION_NAME}' already exists.")
    except Exception:
        logger.info(f"Creating Qdrant collection '{QDRANT_COLLECTION_NAME}'.")

        vector_size = embedding_model.get_sentence_embedding_dimension()
        qdrant_client.create_collection(
            collection_name=QDRANT_COLLECTION_NAME,
            vectors_config=models.VectorParams(size=vector_size, distance=models.Distance.COSINE)
        )

        try:
            with open('jokes.json', 'r', encoding='utf-8') as f:
                jokes = json.load(f)
        except FileNotFoundError:
            logger.error("jokes.json not found. Please create the file.")
            return

        documents = list(jokes.values())
        
        logger.info("Generating embeddings for documents...")
        vectors = embedding_model.encode(documents, show_progress_bar=True)

        qdrant_client.upload_points(
            collection_name=QDRANT_COLLECTION_NAME,
            points=[
                models.PointStruct(id=idx, vector=vector.tolist(), payload={"text": doc})
                for idx, (vector, doc) in enumerate(zip(vectors, documents))
            ],
            wait=True
        )
        logger.info("Successfully populated Qdrant collection.")

# --- RAG Helper Function ---
def get_rag_response(prompt: str):
    """Retrieves context, generates a response, and returns both."""
    try:
        query_vector = embedding_model.encode(prompt).tolist()

        search_result = qdrant_client.search(
            collection_name=QDRANT_COLLECTION_NAME,
            query_vector=query_vector,
            limit=6
        )

        relevant_jokes_list = [hit.payload.get("text", "") for hit in search_result] if search_result else []
        context_jokes = '\n\n__________'.join(relevant_jokes_list)

        augmented_prompt = (
            f"–¢–µ–±–µ –±—É–¥–µ—Ç –¥–∞–Ω–æ —à–µ—Å—Ç—å –∞–Ω–µ–∫–¥–æ—Ç–æ–≤ –∏ —Ç–µ–º–∞ –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è. –¢–µ–±–µ –Ω–∞–¥–æ –≤—ã–±—Ä–∞—Ç—å —Å–∞–º—ã–π –ø–æ–¥—Ö–æ–¥—è—â–∏–π –ø–æ–¥ —Ç–µ–º—É –∞–Ω–µ–∫–¥–æ—Ç –∏ –ø–µ—Ä–µ–¥–µ–ª–∞—Ç—å –µ–≥–æ –ø–æ–¥ —Ç–µ–º—É –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è. –ù–µ –¥–æ–±–∞–≤–ª—è–π –Ω–∏–∫–∞–∫–∏—Ö –æ–±—ä—è—Å–Ω–µ–Ω–∏–π –∏–ª–∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è, –æ—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –∞–Ω–µ–∫–¥–æ—Ç–æ–º.\n\n"
            "–ü–†–ò–ú–ï–† –ü–ï–†–ï–î–ï–õ–´–í–ê–ù–ò–Ø 1:\n\n"
            "–¢–ï–ú–ê –ê–ù–ï–ö–î–û–¢–ê: –û—Ç–Ω–æ—à–µ–Ω–∏—è –°—Ç–µ–ø–∞–Ω–∞ –∏ –µ–≥–æ –∂–µ–Ω—ã\n\n"
            """–ê–ù–ï–ö–î–û–¢ –î–õ–Ø –ü–ï–†–ï–î–ï–õ–ö–ò:–ú—É–∂–∏–∫—É –∑–≤–æ–Ω—è—Ç –∏–∑ –º–∏–ª–∏—Ü–∏–∏ –∏ –≥–æ–≤–æ—Ä—è—Ç:
‚Äî –£ –Ω–∞—Å –¥–ª—è –≤–∞—Å —Ç—Ä–∏ –Ω–æ–≤–æ—Å—Ç–∏ ‚Äî –ø–ª–æ—Ö–∞—è, —Ö–æ—Ä–æ—à–∞—è –∏ –æ—Ö—É–µ–Ω–Ω–∞—è.
‚Äî –ì–º, –Ω—É –¥–∞–≤–∞–π—Ç–µ —Å –ø–ª–æ—Ö–æ–π.
‚Äî –í–∞—à–∞ –∂–µ–Ω–∞ –ø–æ–≥–∏–±–ª–∞ ‚Äî —É—Ç–æ–Ω—É–ª–∞ –≤ —Ä–µ–∫–µ.
‚Äî –ê —Ö–æ—Ä–æ—à–∞—è?
‚Äî –ö–æ–≥–¥–∞ –º—ã –µ–µ –¥–æ—Å—Ç–∞–ª–∏ ‚Äî –µ–µ —Ç–µ–ª–æ –±—ã–ª–æ –æ–±–ª–µ–ø–ª–µ–Ω–æ —Ä–∞–∫–∞–º–∏ –∏ –º—ã –∑–∞–µ–±–∞—Ç–æ –ø–æ–ø–∏–ª–∏ –ø–∏–≤–æ –≤—Å–µ–º –æ—Ç–¥–µ–ª–æ–º.
‚Äî –ì–º, –∞ –æ—Ö—É–µ–Ω–Ω–∞—è —Ç–æ–≥–¥–∞ –∫–∞–∫–∞—è?‚Äî –ú—ã –µ–µ —Å–Ω–æ–≤–∞ –∑–∞–±—Ä–æ—Å–∏–ª–∏ –≤ —Ä–µ–∫—É –∏ –ø—Ä–∏–≥–ª–∞—à–∞–µ–º –≤–∞—Å –∑–∞–≤—Ç—Ä–∞ –Ω–∞ –ø–∏–≤–æ!)
\n\n"""
            """–ü–ï–†–ï–î–ï–õ–ê–ù–ù–´–ô –ê–ù–ï–ö–î–û–¢:–°—Ç–µ–ø–∞–Ω—É –∑–≤–æ–Ω—è—Ç –∏–∑ –º–∏–ª–∏—Ü–∏–∏ –∏ –≥–æ–≤–æ—Ä—è—Ç:
‚Äî –°—Ç–µ–ø–∞–Ω, –∑–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ, —É –Ω–∞—Å –¥–ª—è –≤–∞—Å —Ç—Ä–∏ –Ω–æ–≤–æ—Å—Ç–∏ ‚Äî –ø–ª–æ—Ö–∞—è, —Ö–æ—Ä–æ—à–∞—è –∏ –æ—Ö—É–µ–Ω–Ω–∞—è.
‚Äî –ì–º, –Ω—É –¥–∞–≤–∞–π—Ç–µ —Å –ø–ª–æ—Ö–æ–π.
‚Äî –í–∞—à–∞ –∂–µ–Ω–∞ –ø–æ–≥–∏–±–ª–∞ ‚Äî —É—Ç–æ–Ω—É–ª–∞ –≤ —Ä–µ–∫–µ.
‚Äî –ê —Ö–æ—Ä–æ—à–∞—è?
‚Äî –ö–æ–≥–¥–∞ –º—ã –µ–µ –¥–æ—Å—Ç–∞–ª–∏ ‚Äî –µ–µ —Ç–µ–ª–æ –±—ã–ª–æ –æ–±–ª–µ–ø–ª–µ–Ω–æ —Ä–∞–∫–∞–º–∏ –∏ –º—ã –∑–∞–µ–±–∞—Ç–æ –ø–æ–ø–∏–ª–∏ –ø–∏–≤–æ –≤—Å–µ–º –æ—Ç–¥–µ–ª–æ–º.
‚Äî –ì–º, –∞ –æ—Ö—É–µ–Ω–Ω–∞—è —Ç–æ–≥–¥–∞ –∫–∞–∫–∞—è?‚Äî –ú—ã –µ–µ —Å–Ω–æ–≤–∞ –∑–∞–±—Ä–æ—Å–∏–ª–∏ –≤ —Ä–µ–∫—É –∏ –ø—Ä–∏–≥–ª–∞—à–∞–µ–º –≤–∞—Å –∑–∞–≤—Ç—Ä–∞ –Ω–∞ –ø–∏–≤–æ!)
\n\n"""
            f"–ê–ù–ï–ö–î–û–¢–´, –û–î–ò–ù –ò–ó –ö–û–¢–û–†–´–• –ù–ê–î–û –ü–ï–†–ï–î–ï–õ–ê–¢–¨:\n\"{context_jokes}\"\n\n"
            f"–¢–ï–ú–ê –û–¢ –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø:\n\"{prompt}\""
        )

        response = openai_client.chat.completions.create(
            model="Qwen/Qwen3-235B-A22B-Instruct-2507",
            max_tokens=1024,
            temperature=0.8,
            messages=[
                {"role": "system", "content": "–¢—ã ‚Äî –∫—Ä–µ–∞—Ç–∏–≤–Ω—ã–π –ò–ò-—é–º–æ—Ä–∏—Å—Ç. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–æ—Ä–∏—é —é–º–æ—Ä–∞, –ø—Ä–∏–º–µ—Ä –∏ —Ç–µ–º—É –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –∞ –∑–∞—Ç–µ–º —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –Ω–∞ —ç—Ç–æ–π –æ—Å–Ω–æ–≤–µ –æ—Å—Ç—Ä–æ—É–º–Ω—É—é —à—É—Ç–∫—É."},
                {"role": "user", "content": augmented_prompt}
            ]
        )
        generated_joke = response.choices[0].message.content
        return generated_joke, relevant_jokes_list
    except Exception as e:
        logger.error(f"RAG process failed: {e}")
        return "–ò–∑–≤–∏–Ω–∏—Ç–µ, —É –º–µ–Ω—è —Ç–≤–æ—Ä—á–µ—Å–∫–∏–π –∫—Ä–∏–∑–∏—Å. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.", []

# --- Bot Handlers ---
@bot.message_handler(commands=['start'])
def send_welcome(message):
    """Sends a welcome message when the /start command is issued."""
    bot.reply_to(message, "–ü—Ä–∏–≤–µ—Ç! –î–∞–≤–∞–π-–∫–∞ –ø–æ—à—É—Ç–∫—É–µ–º. –ö–∏–¥–∞–π —Ç–µ–º—É, —è –ø–æ–ø—Ä–æ–±—É—é –ø—Ä–∏–¥—É–º–∞—Ç—å –∞–Ω–µ–∫–¥–æ—Ç.")

@bot.message_handler(func=lambda message: True)
def handle_message(message):
    """Handles messages, gets a joke, logs it, and sends it with vote buttons."""
    if message.text.startswith('/'):
        return

    response_text, relevant_jokes = get_rag_response(message.text)
    
    joke_id = str(uuid.uuid4())
    jokes_sent[joke_id] = response_text
    
    log_entry = {
        'id': joke_id,
        'prompt': message.text,
        'generated_joke': response_text,
        'rating': 0,
        'relevant_jokes': relevant_jokes
    }
    append_log_entry(log_entry)
    
    markup = InlineKeyboardMarkup()
    upvote_button = InlineKeyboardButton("üëç", callback_data=f"vote:up:{joke_id}")
    downvote_button = InlineKeyboardButton("üëé", callback_data=f"vote:down:{joke_id}")
    markup.add(upvote_button, downvote_button)
    
    bot.reply_to(message, response_text, reply_markup=markup)

@bot.callback_query_handler(func=lambda call: call.data.startswith('vote:'))
def handle_vote(call):
    """Handles button presses, updates the log file, and removes buttons."""
    try:
        _, action, joke_id = call.data.split(':')
        rating = 1 if action == 'up' else -1
        
        update_log_rating(joke_id, rating)
        
        joke_text = jokes_sent.get(joke_id, "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∞–Ω–µ–∫–¥–æ—Ç")
        logger.info(f"User '{call.from_user.username}' voted '{action}' for joke: '{joke_text[:70]}...'")
        
        bot.answer_callback_query(call.id, text="–°–ø–∞—Å–∏–±–æ –∑–∞ –æ—Ü–µ–Ω–∫—É!")
        bot.edit_message_reply_markup(chat_id=call.message.chat.id, message_id=call.message.message_id, reply_markup=None)
    except Exception as e:
        logger.error(f"Error handling vote: {e}")
        bot.answer_callback_query(call.id, text="–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≥–æ–ª–æ—Å–∞.")

def main():
    """Set up Qdrant and start the bot."""
    setup_qdrant()
    print("Bot is running... Press Ctrl+C to stop.")
    bot.infinity_polling()

if __name__ == '__main__':
    main()

